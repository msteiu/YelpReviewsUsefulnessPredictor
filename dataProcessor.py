# dataProcessor.py
# CS 232 final project
# Team: MLH
# author: Lisa Huang
# date: 04/12/18
# modified: 05/20/18
# supported by Python 2

"""
A Python script that cleans the original 5 million review data based on language, business category, review length, 
and number of votes in the "useful" category.

***Only the final products of this file, useful650000.json and useless650000.json, are included in the package, as the 
intermediary are too large.***
"""

import json
import re
import operator
from langdetect import DetectorFactory
DetectorFactory.seed = 0
from langdetect import detect


"""
iterparse() and writeToJSON():
Convert the original review file, a json file of json objects, into a json file containing
a list of json objects.

Original file:
{"text":..., "business_id":..., ... }
{"text":..., "business_id":..., ... }
...
{"text":..., "business_id":..., ... }

Converted file:
[{"text":..., "business_id":..., ... },
 {"text":..., "business_id":..., ... },
 {"text":..., "business_id":..., ... },
 ...
 {"text":..., "business_id":..., ... }] 
"""
nonspace = re.compile(r'\S')
def iterparse(j):
    decoder = json.JSONDecoder()
    pos = 0
    while True:
        matched = nonspace.search(j, pos)
        if not matched:
            break
        pos = matched.start()
        decoded, pos = decoder.raw_decode(j, pos)
        yield decoded

def writeToJSON(filename, newFile):
    with open(filename, "r") as data_file:
        rawdata = data_file.read()

    data = []
    for decoded in iterparse(rawdata):
        data.append(decoded)
    with open(newFile, "w") as file:
        json.dump(data, file)

"""
sortBusiness():
Generates a dictionary with business IDs as keys and business categories as values.

e.g.
{"12345": ["Restaurant", "Mexican"],
 "56789": ["Dentist", "Oral Surgery"],
 ...}
"""
def sortBusiness(data):
    result = {}
    for d in data:
        bID = d["business_id"]
        result[bID] = d["categories"]
    return result

"""
findCategories():
Uses the dictionary generated by sortBusiness(), returns all business categories mentioned in the raw file.
"""
def findCategories(businessDict):
    result = []
    for key in businessDict: #
        categories = businessDict[key]
        for category in categories:
            result.append(category)
    return list(set(result))

"""
frequencyOfCategories():
Returns a dictionary with business categories as keys and the number of their appearances in the raw review file as
values. We use this dictioanry to find out which business category has the most number of reviews.
"""
def frequencyOfCategories(reviewData, businessData):
    businessDict = sortBusiness(businessData)
    categories = findCategories(businessDict)

    with open(reviewFile, "r") as f:
        reviews = json.load(f)

    frequencyDict = {}

    for category in categories:
        frequencyDict[category] = 0

    for review in reviewData:
        businessID = review["business_id"]
        if businessID in businessDict:
            # business categories of one business
            categoriesOfOne = businessDict[businessID]

            for c in categoriesOfOne:
                frequencyDict[c] += 1

    return frequencyDict

"""
findBusinessByCategory():
Based on the dictionary returned by frequencyOfCategories(), finds all businesses related to that category.
Returns a dictionary with business IDs as keys and a 0 (a random number by default) as values.
We decided to use a dictionary/hashtable rather than a list for fast information retrieval.
"""
def findBusinessByCategory(businessData, category):
    businessDict = sortBusiness(businessData)
    idDict = {}
    for key in businessDict:
        if category in businessDict[key]:
            idDict[key] = 0
    return idDict

"""
Modified on 04/22/18

findReviewsByID():
Finds all English reviews about businesses in the dictionary returned by findBusinessByCategory(), and puts the reviews
into an output file.
"""
def findReviewsByID(reviews, idDict, outFile):
    targets = []
    for i in range(len(reviews)):
    	review = reviews[i]
    	# print(str(i))
        if review["business_id"] in idDict:
            try:
                review_lang = detect(review["text"])
                if review_lang == "en":
                    targets.append(review)
            # skip reviews that are not in English
            except:
                continue

    with open(outFile, "w") as file:
        json.dump(targets, file)

"""
getReviewByLength():
Returns a dictionary with length ranges of reviews as keys and the number of reviews within the ranges as values. 
"""
def getReviewLength(reviews):
    distribution = {}
    for i in range(len(reviews)):
        review = reviews[i]
        # print(i)
        text = review["text"]
        length = len(text)
        review["character count"] = length

        lowerRange = length/100*100
        lenRange = str(lowerRange) + "-" + str(lowerRange+100)

        if lenRange not in distribution:
            distribution[lenRange] = 1
        else:
            distribution[lenRange] += 1

    return distribution

"""
reviewByLength():
Returns the number of reviews with length of 100-599 characters. Wrties these reviews into a json file.
"""
def reviewByLength(reviewData, outFile):
    reviews = []
    for i in range(len(reviewData)):
        review = reviewData[i]
        print(i)
        text = review["text"]
        length = len(text)
        if "character count" not in review:
            review["character count"] = length
        if length >= 100 and length <  600:
            reviews.append(review)
    with open(outFile, "w") as f:
        json.dump(reviews, f)
        print("new file is written.")
        
    return len(reviews)

"""
countVote():
Returns the dictionary which shows the number of reviews with "useful" votes and number of reviews without "useful" votes 
in the file created by reviewByLength()
"""
def countVote(reviewData):
    result = {"useful": 0, "useless": 0}
    for i in range(len(reviewData)):
        print(i)
        review = reviewData[i]
        if review["useful"] > 0:
            result["useful"] += 1
        else:
            result ["useless"] += 1
    return result


"""
splitFile():
Based on the distribution of "useful" and "useless" votes, keeps only 650,000 reviews of each category and writes the reviews 
into separate files. 
"""
def splitFile(reviewData, out1, out2):
    useful = []
    useless = []
    for review in reviewData:
        if review["useful"] > 0 and len(useful) < 650000:
            useful.append(review)
        elif review["useful"] == 0 and len(useless) < 650000:
            useless.append(review)

    with open(out1, "w") as f1:
        json.dump(useful, f1)
        print("file1 is written.")
    with open(out2, "w") as f2:
        json.dump(useless, f2)
        print("file2 is written.")

    return (len(useful), len(useless))


if __name__ == "__main__":
    # Convert original JSON files to structured JSON files
    writeToJSON("review.json", "reviewJSON.json")
    writeTOJSON("business.json", "businessJSON.json")

    # Load the data
    with open("reviewJSON.json", "r") as f1:
        reviewData = json.load(f1)
        f1.close()
    with open("businessJSON.json", "r") as f2:
        businessData = json.load(f2)
        f2.close()

    # Find the category with most number of reviews
    categoryByFrequency = frequencyOfCategories(reviewData, businessData)
    maximum = max(categoryByFrequency.iteritems(), key=operator.itemgetter(1))
    print(maximum) # (u'Restaurants', 3221419)
    category = maximum[0] # u'Restaurants'

    # Find all reviews related to the "Restaurant" category
    idDict = findBusinessByCategory(businessData, category)
    findReviewsByID(reviewData, idDict, "review_restaurants.json")

    # Load the restaurant reviews
    with open("review_restaurants.json", "r") as f3:
        restaurant_reviews = json.load(f3)
        f3.close()

    # Focus on reviews whose lengths fall between a certain length range, in this case 100-599 characters
    lenDist = getReviewsLength(restaurant_reviews)
    print(lenDist)
    # After seeing the length distribution from lenDist, we decided to keep the reviews between 100 and 599 characters
    num_reviews = reviewByLength(restaurant_reviews, "review_restaurants_100-599.json")

    # Load the retaurant reviews with 100-599 characters
    with open("review_restaurants_100-599.json", "r") as f4:
        restaurant_reviews = json.load(f4)
        f4.close()

    # Split the reviews into equal numbers of "useful" and "useless" reviews
    voteDist = countVote(restaurant_reviews) #{'useful': 699148, 'useless': 1278119}
    num_useful, num_useless = splitFile(restaurant_reviews, "useful650000.json", "useless650000.json") #650000, 650000
